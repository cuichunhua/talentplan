﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿﻿# 1.部署环境## 1.1 node```共使用 4 台物理服务器- node1 tidb * 1    prometheus * 1   grafana * 1- node2 pd * 1    tikv * 1- node3 pd * 1    tikv * 1- node4 pd * 1    tikv * 1```## 1.2 硬件配置```cpu：  E5-2620v3 *2   40 vcoresmemory：  8*16Gdisk： 8* 480G SSD(RAID 50)```## 1.3 配置```v4.0.0tidb 配置alter-primary-key = falsecompatible-kill-query = falseenable-streaming = falsehost = "0.0.0.0"lease = "45s"lower-case-table-names = 2oom-action = "log"run-ddl = trueserver-version = ""socket = ""split-table = truestore = "tikv"token-limit = 1000skip-grant-table=true[binlog]ignore-error = falsewrite-timeout = "15s"[experimental]allow-auto-random = false[log]disable-timestamp = falseexpensive-threshold = 10000format = "text"level = "info"query-log-max-len = 2048slow-threshold = 300[log.file]max-backups = 0max-days = 0max-size = 300[opentracing]enable = falserpc-metrics = false[opentracing.reporter]buffer-flush-interval = 0local-agent-host-port = ""log-spans = falsequeue-size = 0[opentracing.sampler]max-operations = 0param = 1.0sampling-refresh-interval = 0sampling-server-url = ""type = "const"[performance]cross-join = truefeedback-probability = 0.05force-priority = "NO_PRIORITY"max-procs = 0pseudo-estimate-ratio = 0.8query-feedback-limit = 1024run-auto-analyze = truestats-lease = "3s"stmt-count-limit = 5000tcp-keep-alive = true[pessimistic-txn]enable = truemax-retry-count = 256[prepared-plan-cache]capacity = 100enabled = falsememory-guard-ratio = 0.1[proxy-protocol]header-timeout = 5networks = ""[security]cluster-ssl-ca = ""cluster-ssl-cert = ""cluster-ssl-key = ""ssl-ca = ""ssl-cert = ""ssl-key = ""[status]report-status = true[tikv-client]commit-timeout = "41s"grpc-connection-count = 16grpc-keepalive-time = 10grpc-keepalive-timeout = 3[txn-local-latches]capacity = 2048000enabled = falsetikv 配置[coprocessor][gc][import][metric][pd][pessimistic-txn][raftdb][raftdb.defaultcf][raftstore]raftdb-path = ""sync-log = true[readpool][readpool.coprocessor][readpool.storage][rocksdb]wal-dir = ""[rocksdb.defaultcf][rocksdb.defaultcf.titan][rocksdb.lockcf][rocksdb.titan][rocksdb.writecf][security]ca-path = ""cert-path = ""key-path = ""[server][server.labels][storage][storage.block-cache]```# 2. 压测## 2.1  sysbench- Point select 测试   ```time:300ssysbench --config-file=./bm_config_run oltp_point_select --threads=128 --tables=32 --table-size=10000000 runsysbench --config-file=./bm_config_run oltp_point_select --threads=512 --tables=32 --table-size=10000000 runsysbench --config-file=./bm_config_run oltp_point_select --threads=1024 --tables=32 --table-size=10000000 run```threads|tps|qps|min latency|avg latency|95th latency|max latency--|:--:|:--:|:--:|:--|:--:|--:128|117136|117136|0.22|1.09|2.91|43.06512|124807|124807|0.23|4.10|10.46|48.681024|125858|125858|0.30|8.13|21.11|93.39- update index 测试   ```time:300ssysbench --config-file=./bm_config_run oltp_update_index --threads=128 --tables=32 --table-size=10000000 runsysbench --config-file=./bm_config_run oltp_update_index --threads=512 --tables=32 --table-size=10000000 runsysbench --config-file=./bm_config_run oltp_update_index --threads=1024 --tables=32 --table-size=10000000 run```threads|tps|qps|min latency|avg latency|95th latency|max latency--|:--:|:--:|:--:|:--|:--:|--:128|12643|12643|0.39|10.12|16.12|216.08512|16852|16852|0.42|30.37|51.02|444.731024|19429|19429|0.74|52.68|90.78|326.71- read write 测试   ```time:300ssysbench --config-file=./bm_config_run oltp_read_write --threads=128 --tables=32 --table-size=10000000 runsysbench --config-file=./bm_config_run oltp_read_write --threads=512 --tables=32 --table-size=10000000 run```threads|tps|qps|min latency|avg latency|95th latency|max latency--|:--:|:--:|:--:|:--|:--:|--:128|2448|48963|14.51|52.26|73.13|417.15512|2469|49384|28.14|207.03|297.92|569.64## 2.2  go-ycsb- workloada ``` Update heavy workload: mix of 50/50 reads and writesgo-ycsb load mysql -P workloads/workloada -p recordcount=10000000 -p mysql.host=127.0.0.1 -p mysql.port=4000 --threads 256go-ycsb run mysql -P workloads/workloada -p operationcount=10000000 -p mysql.host=127.0.0.1 -p mysql.port=4000 --threads 256```- workloadb```Read mostly workload: Read/update ratio: 95/5```- workloadc``` Read only: Read/update ratio: 100/0```- workloadd``` Read latest workload: Read/update/insert ratio: 95/0/5```- workloade``` Short ranges: Scan/insert ratio: 95/5```- workloadf``` Read-modify-write workload: Read/read-modify-write ratio: 50/50```*latency: us*type|threads|ops|min latency|avg latency|99th latency|99.9th latency|99.99th latency|max latency--|:--|:--:|:--:|:--:|:--|:--:|:--:|:--:|--:workloada-Read|256|15832|561|1978 |10000|27000|41000|491061workloada-Upd|256|15832|1917|13933|191000|228000|387000|1156935b-Read|256|54051|546|4264|18000|29000|42000|54044b-Upd|256|2838|1960|8347|27000|184000|216000|399257f-Read|256|28294|552|2183|11000|20000|41000|207908f-READ_MODIFY_WRITE|256|14149|2543|15662|191000|228000|383000|1045644f-Upd|256|14149|1874|13454|189000|225000|381000|1044423## 2.3  go-tpc```go-tpc tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 100 preparego-tpc tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 100 run --time 5m  --threads 256[mysql] 2020/08/23 16:10:38 packets.go:412: busy buffer[mysql] 2020/08/23 16:10:38 statement.go:49: invalid connectionFinished[Summary] DELIVERY - Takes(s): 299.4, Count: 28137, TPM: 5638.7, Sum(ms): 8904081, Avg(ms): 316, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 8000[Summary] DELIVERY_ERR - Takes(s): 299.4, Count: 26, TPM: 5.2, Sum(ms): 4072, Avg(ms): 156, 90th(ms): 512, 99th(ms): 512, 99.9th(ms): 512[Summary] NEW_ORDER - Takes(s): 299.5, Count: 315762, TPM: 63248.8, Sum(ms): 34200452, Avg(ms): 108, 90th(ms): 160, 99th(ms): 512, 99.9th(ms): 4000[Summary] NEW_ORDER_ERR - Takes(s): 299.5, Count: 107, TPM: 21.4, Sum(ms): 5106, Avg(ms): 47, 90th(ms): 96, 99th(ms): 256, 99.9th(ms): 256[Summary] ORDER_STATUS - Takes(s): 299.6, Count: 28173, TPM: 5642.9, Sum(ms): 590784, Avg(ms): 20, 90th(ms): 40, 99th(ms): 64, 99.9th(ms): 256[Summary] ORDER_STATUS_ERR - Takes(s): 299.6, Count: 2, TPM: 0.4, Sum(ms): 36, Avg(ms): 18, 90th(ms): 32, 99th(ms): 32, 99.9th(ms): 32[Summary] PAYMENT - Takes(s): 299.7, Count: 302460, TPM: 60550.6, Sum(ms): 31650484, Avg(ms): 104, 90th(ms): 192, 99th(ms): 512, 99.9th(ms): 1500[Summary] PAYMENT_ERR - Takes(s): 299.7, Count: 83, TPM: 16.6, Sum(ms): 5813, Avg(ms): 70, 90th(ms): 160, 99th(ms): 512, 99.9th(ms): 512[Summary] STOCK_LEVEL - Takes(s): 299.7, Count: 27815, TPM: 5569.4, Sum(ms): 883379, Avg(ms): 31, 90th(ms): 48, 99th(ms): 64, 99.9th(ms): 256tpmC: 63248.8go-tpc tpcc -H 127.0.0.1 -P 4000 -D tpcc --warehouses 100 run --time 5m --threads 512[mysql] 2020/08/23 16:20:25 statement.go:49: invalid connection[mysql] 2020/08/23 16:20:25 packets.go:412: busy buffer[mysql] 2020/08/23 16:20:25 packets.go:412: busy buffer[mysql] 2020/08/23 16:20:25 statement.go:97: invalid connection[mysql] 2020/08/23 16:20:25 statement.go:97: invalid connection[mysql] 2020/08/23 16:20:25 statement.go:97: invalid connectionFinished[Summary] DELIVERY - Takes(s): 298.8, Count: 31279, TPM: 6281.7, Sum(ms): 13840046, Avg(ms): 442, 90th(ms): 1000, 99th(ms): 1500, 99.9th(ms): 2000[Summary] DELIVERY_ERR - Takes(s): 298.8, Count: 37, TPM: 7.4, Sum(ms): 11185, Avg(ms): 302, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 1000[Summary] NEW_ORDER - Takes(s): 299.1, Count: 354108, TPM: 71033.2, Sum(ms): 61048030, Avg(ms): 172, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 1500[Summary] NEW_ORDER_ERR - Takes(s): 299.1, Count: 175, TPM: 35.1, Sum(ms): 18920, Avg(ms): 108, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 1000[Summary] ORDER_STATUS - Takes(s): 299.2, Count: 31348, TPM: 6285.6, Sum(ms): 876113, Avg(ms): 27, 90th(ms): 64, 99th(ms): 80, 99.9th(ms): 128[Summary] ORDER_STATUS_ERR - Takes(s): 299.2, Count: 1, TPM: 0.2, Sum(ms): 23, Avg(ms): 23, 90th(ms): 24, 99th(ms): 24, 99.9th(ms): 24[Summary] PAYMENT - Takes(s): 299.3, Count: 338275, TPM: 67807.4, Sum(ms): 75713891, Avg(ms): 223, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 1500[Summary] PAYMENT_ERR - Takes(s): 299.3, Count: 222, TPM: 44.5, Sum(ms): 38050, Avg(ms): 171, 90th(ms): 512, 99th(ms): 1000, 99.9th(ms): 1000[Summary] STOCK_LEVEL - Takes(s): 299.3, Count: 31599, TPM: 6334.0, Sum(ms): 1177393, Avg(ms): 37, 90th(ms): 64, 99th(ms): 96, 99.9th(ms): 128[Summary] STOCK_LEVEL_ERR - Takes(s): 299.3, Count: 3, TPM: 0.6, Sum(ms): 45, Avg(ms): 15, 90th(ms): 20, 99th(ms): 20, 99.9th(ms): 20tpmC: 71033.2tpcc 当并发线程达到256+，开始出现无效连接。```# 3. 总结- 测试过程中对应的监控数据（grafana截图和profiling）详见 benchmark 目录，地址：https://github.com/cuichunhua/talentplan/tree/master/benchmark。- 测试开启乐观事务加载，悲观事务压测。- sysbench默认表结构是针对MySQL的，主键自增，不适合分布式的tidb，写入热点明显，32张表，每张表1千w数据，磁盘写入大概75G（单副本）。- 针对 sysbench 共进行了3种类型的测试，点查、索引更新、读写，latency依次增加，go-ycsb表现也类似，共进行了读写（1:1）、读更新（95：5）、读修改写（1：1），最后验证的tpcc，并发超过256以上，开始出现无效连接，测试终止。- tidb 的时间消耗主要在 runtime包的syscall、mallocgc、scanobject等。